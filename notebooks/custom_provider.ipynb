{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Building a Custom Data Provider\n",
    "Data providers take data and return data in a format that can be used by the model. In this case the input data will be the IAM Dataset that we preprocess in ```/data/IAM```\n",
    "\n",
    "X-rayLaser gives [instructions](https://github.com/X-rayLaser/pytorch-handwriting-synthesis-toolkit?tab=readme-ov-file#implementing-custom-data-provider). This is my attempt to implement a custom data provider along with my learnings.\n",
    "\n",
    "I set out to gain a better understanding of:\n",
    "- Classes in python\n",
    "- Generators\n",
    "- Iterators\n",
    "- Yield keyword\n",
    "- Bounded Iterator\n",
    "- Transformations to the data\n",
    "- Format of the data for the model"
   ],
   "id": "d0cf1421ecb166f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Learnings\n",
    "## 1. Classes in python\n",
    "Classes allow creating complex datastructures that can contain both data and functions.\n",
    "- Contain __init__ function that initializes the class\n",
    "- ```self``` refers to the instance of the class\n",
    "- Methods below to the class and require ```self``` as the first argument\n",
    "- Three primary use-cases of classes:\n",
    "    - Represent real-world objects that have attributes and behaviours\n",
    "    - Bundling related functions and data together\n",
    "    - Want modular reusable code\n",
    "- Important difference between classes and functions is that classes are \"stateful\" meaning they can retain state across method calls through instance attributes. Functions are \"stateless\" and do not retain state across calls.\n",
    "- Static methods (denoted ```@staticmethod``` above the function) are methods that belong to the class and not the instance. They can be called without creating an instance of the class and do not have access to the instance attributes. ```self``` is not required as an argument. \n",
    "- Class can inheret from another class by passing the parent class as an argument in the class definition.\n",
    "    ```\n",
    "    class ChildClass(ParentClass):\n",
    "        # rest of the class\n",
    "    ```"
   ],
   "id": "95415b5b19074017"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Iterators, Generators, and the Yield Keyword\n",
    "Iterators are objects that can be iterated over that return one element at a time.\n",
    "\n",
    "They must contain the ```__iter__``` method which returns the iterator object itself.\n",
    "\n",
    "Must also contain either the ```__next__``` method use the ```yield``` keyword to return the next value. \n",
    "\n",
    "The ```yield``` keyword turns a function into a generator. When yield is called, it pauses the function, saving its state, and returns the yielded value. When the generator is iterated over, it resumes execution immediately after the last yield run.\n",
    "\n",
    "Practically, you should use the ```__next__``` method for more control over the iteration process and ```yield``` for simple iteration.\n",
    "\n",
    "Generators are useful for large datasets that can't fit into memory. They can be used to load data in chunks and process them one at a time.\n",
    "\n",
    "```\n",
    "Example Generator\n",
    "def my_generator(start, end):\n",
    "    current = start\n",
    "    while current < end:\n",
    "        yield current\n",
    "        current += 1\n",
    "\n",
    "# Using a generator\n",
    "for num in my_generator(1, 5):\n",
    "    print(num)  # Output: 1 2 3 4\n",
    "```"
   ],
   "id": "b4764e82b0ae47f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Custom Data Provider",
   "id": "178c46328c384937"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T20:51:19.521553Z",
     "start_time": "2024-07-12T20:51:19.514906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First an Iterator Object to return the strokes and transcript\n",
    "\n",
    "class CustomIterator:\n",
    "    def __init__(self, data_dir):\n",
    "        # Initializes the CustomIAM with the directory containing data files.\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Yields strokes and transcript from each file in the directory.\n",
    "        for file in self.file_names(self.data_dir):\n",
    "            try:\n",
    "                strokes, transcript = self.get_data(file)\n",
    "                yield strokes, transcript\n",
    "            except (FileNotFoundError, pickle.UnpicklingError) as e:\n",
    "                print(f\"Error loading {file}: {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def file_names(path):\n",
    "        # Generates file names in the given directory.\n",
    "        try:\n",
    "            for x in os.listdir(path):\n",
    "                yield x\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Directory not found: {e}\")\n",
    "            return\n",
    "\n",
    "    def get_data(self, file):\n",
    "        # Loads data from a pickle file.\n",
    "        file_path = os.path.join(self.data_dir, file)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            content = pickle.load(f)\n",
    "        \n",
    "        transcript = content['transcript']\n",
    "        strokes = content['strokes']\n",
    "\n",
    "        return strokes, transcript"
   ],
   "id": "52234b6c3ec5fbeb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T20:59:12.490310Z",
     "start_time": "2024-07-12T20:59:12.330441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# And second a Custom Data Provider that uses the Iterator Object\n",
    "class CustomDataProvider(DataSplittingProvider):\n",
    "    # The class inherits from the DataSplittingProvider class.\n",
    "    # More on the DataSplittingProvider below.\n",
    "    name = 'custom_iam'\n",
    "    # The name of the data provider. This is used to select the provider when using the CLI to prepare the data.\n",
    "    \n",
    "    def __init__(self, training_data_size, validation_data_size=0, data_dir=None):\n",
    "        if data_dir is None:\n",
    "            raise ValueError(\"No data directory specified. Please provide a valid data directory.\")\n",
    "        \n",
    "        training_data_size, validation_data_size = self._parse_args(training_data_size,\n",
    "                                                                    validation_data_size)\n",
    "     \n",
    "        # Initializes the CustomIterator with the data directory.\n",
    "        iterator = self.get_generator(training_data_size, validation_data_size, data_dir)\n",
    "        \n",
    "        # Initializes the DataSplittingProvider with the CustomIterator\n",
    "        super().__init__(iterator, training_data_size, validation_data_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_args(training_data_size, validation_data_size):\n",
    "        return int(training_data_size), int(validation_data_size)\n",
    "\n",
    "    # The get_generator method returns a generator that yields strokes and transcript from the IAM dataset.\n",
    "    def get_generator(self, training_data_size, validation_data_size, data_dir):\n",
    "        \n",
    "        # Initializes the CustomIAM with the data directory.\n",
    "        db = CustomIAM(data_dir)\n",
    "\n",
    "        # If validation data size is specified, the generator yields a total of training_data_size + validation_data_size examples.\n",
    "        if validation_data_size:\n",
    "            num_examples = training_data_size + validation_data_size\n",
    "            it = bounded_iterator(db, num_examples)\n",
    "        else:\n",
    "            it = db.__iter__()\n",
    "\n",
    "        for strokes, text in it:\n",
    "            yield strokes, text\n"
   ],
   "id": "e1b715e87b519e03",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataSplittingProvider' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# And second a Custom Data Provider that uses the Iterator Object\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mCustomDataProvider\u001B[39;00m(\u001B[43mDataSplittingProvider\u001B[49m):\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;66;03m# The class inherits from the DataSplittingProvider class.\u001B[39;00m\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m# More on the DataSplittingProvider below.\u001B[39;00m\n\u001B[1;32m      5\u001B[0m     name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcustom_iam\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;66;03m# The name of the data provider. This is used to select the provider when using the CLI to prepare the data.\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'DataSplittingProvider' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cbf31fb20709c2b3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
